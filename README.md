# PX4-MAVSDK-DroneSwarm-DroughtRecognition âœ…

**Sena DURMAZ, Arda YILDIZ, Bahattin Eren YILDIRIM, Buse KÃœÃ‡ÃœKKÃ–MÃœRCÃœ, TÃ¼rkay Ã–ZBEK**

---

## Genel BakÄ±ÅŸ
Bu proje, drone sÃ¼rÃ¼mleri (swarm) tarafÄ±ndan toplanan gÃ¶rÃ¼ntÃ¼ler ile LoveDA veri kÃ¼mesini kullanarak 7 sÄ±nÄ±flÄ± (Background, Other, Building, Road, Water, Agriculture, Forest) semantic segmentation gerÃ§ekleÅŸtirmeyi amaÃ§lar. Model mimarisi olarak Hugging Face Ã¼zerinden alÄ±nmÄ±ÅŸ ve ADE fine-tuned aÄŸÄ±rlÄ±klarÄ±yla initialize edilmiÅŸ **SegFormer-B3** tercih edilmiÅŸtir. EÄŸitim esnasÄ±nda Exponential Moving Average (EMA), combined loss (Focal + Dice), ve Ã§eÅŸitli augmentasyon teknikleri kullanÄ±lmÄ±ÅŸtÄ±r.

---

## HÄ±zlÄ± BaÅŸlangÄ±Ã§
**Gereksinimler (Ã¶rnek):**
- Python 3.8+
- torch, torchvision
- transformers
- albumentations, albumentations.pytorch
- numpy, Pillow, matplotlib, tqdm

Ã–rnek kurulum:
```
pip install torch torchvision transformers albumentations matplotlib pillow tqdm
```

---

## Veri KÃ¼mesi ve Dizini
- KullanÄ±lan veri: LoveDA
- Beklenen kÃ¶k dizin Ã¶rneÄŸi: `/content/drive/MyDrive/LoveDa-Dataset`
- YapÄ±:
  - `Train/Train/{Urban,Rural}/images_png` ve `masks_png`
  - `Val/Val/{Urban,Rural}/...`
  - `Test/Test/{Urban,Rural}/images_png`
- Maske Ã¶zel durumlarÄ±: `ignore_index = 255` (gÃ¶rmezden gelinir)
- SÄ±nÄ±f sayÄ±sÄ±: 7 (0..6)

---

## Model & EÄŸitim KonfigÃ¼rasyonu (Teknik Detaylar) ğŸ”§
- Model: `SegformerForSemanticSegmentation` ("nvidia/segformer-b3-finetuned-ade-512-512")
- `config.num_labels = 7`
- `ignore_mismatched_sizes=True` ile kÄ±smi yÃ¼klemeye izin veriliyor

EÄŸitim hiperparametreleri (kodda kullanÄ±lan):
- GÃ¶rÃ¼ntÃ¼ boyutu: **512x512**
- Batch size: **8** (train), Test batch size: **2**
- Num workers: **2**
- Epochs: **10** (Ã¶rnek) â€” Ã¶neri: daha yÃ¼ksek epoch sayÄ±larÄ± (30-50) ile deneyin
- Optimizer: **AdamW**, lr = **1e-4**
- Scheduler: **ReduceLROnPlateau**(mode='min', factor=0.5, patience=2)
- Early stopping patience: **3** (validation loss geliÅŸmezse durdurulur)
- EMA: decay = **0.999** (doÄŸrulamada EMA modeli kullanÄ±lÄ±r)
- Mixed precision: tavsiye edilir (AMP) â€” hÄ±z ve bellek kazanÄ±mÄ± iÃ§in

Augmentasyonlar (train):
- Resize(512,512)
- HorizontalFlip(p=0.5), VerticalFlip(p=0.3), RandomRotate90(p=0.5)
- ShiftScaleRotate(shift_limit=0.1, scale_limit=0.1, rotate_limit=15, p=0.5)
- RandomBrightnessContrast, ColorJitter
- Normalize(ImageNet mean/std) + ToTensorV2()

Validation/Test augment: Resize + Normalize + ToTensorV2

---

## KayÄ±p FonksiyonlarÄ± (Loss) ğŸ§ 
- **Focal Loss** (CrossEntropy tabanlÄ±, gamma=2, ignore_index=255)
- **Dice Loss** (one-hot target, softmax on logits, ignore 255)
- **CombinedLoss** = 0.5 * Focal + 0.5 * Dice
- Ã–rnek sÄ±nÄ±f aÄŸÄ±rlÄ±klarÄ± (kodda): `tensor([0.5, 0.8, 1.5, 1.2, 2.2, 3.0, 1.0])`

---

## EÄŸitim DÃ¶ngÃ¼sÃ¼ & Checkpointing
- EÄŸitim sÄ±rasÄ±nda model.train() ile aÄŸÄ±rlÄ±klar gÃ¼ncellenir. EMA modeli paralel olarak gÃ¼ncellenir ve doÄŸrulama EMA ile yapÄ±lÄ±r.
- Validation loss iyileÅŸirse **EMA modelinin aÄŸÄ±rlÄ±klarÄ± kaydedilir**: `best_segformer_b3_ema_.pth`
- Loss hesaplarÄ±nda maske pikselleri `255` ise dÄ±ÅŸlanÄ±r; sÄ±nÄ±flar `torch.clamp(..., max=6)` ile sÄ±nÄ±rlandÄ±rÄ±lÄ±r.

Ã–neriler:
- Reproducibility iÃ§in seed sabitleyin (`torch.manual_seed`, numpy, vb.)
- Logging: TensorBoard / wandb ile metric ve gÃ¶rselleÅŸtirme kaydedin
- Multi-GPU veya DDP kullanacaksanÄ±z batch size ve gradient accumulation planlayÄ±n

---

## Ä°nferans & Post-processing âœ…
- Test-time augmentation: horizontal flip ensemble (orijinal+flip -> average logits)
- Mask post-processing: `refine_agriculture_class` fonksiyonu
  - Yerel 3x3 patch iÃ§inde `Agriculture (5)` yoÄŸunluÄŸu â‰¥ 3 ise Ã§evredeki `Other (1)` pikselleri `Agriculture (5)` olarak dÃ¼zeltilir
  - KÃ¼Ã§Ã¼k boyutta (Ã¶rneÄŸin 128x128) uygulanÄ±p sonra nearest interpolation ile 512x512'ye Ã¶lÃ§eklenir
- Renk haritasÄ± `label_colors` kullanÄ±larak gÃ¶rselleÅŸtirme yapÄ±lÄ±r

---

## Swarm Entegrasyonu (PX4 + MAVSDK) ğŸš
AÅŸaÄŸÄ±da repo iÃ§indeki mevcut scriptlere (Ã¶rn. `drone1.py`, `drone2.py`, `ucak1.py`, `ucak2.py`, `startall.sh`, `stop_all.sh`, `start_video_logger1.py`, `start_video_logger2.py`) dayanarak adÄ±m adÄ±m kullanÄ±m kÄ±lavuzu bulunmaktadÄ±r.

### Ã–ne Ã§Ä±kan dosyalar
- `drone1.py`, `drone2.py` / `ucak1.py`, `ucak2.py`: Her bir drone iÃ§in telemetry toplama, SHM (shared memory) yazma ve flocking (sÃ¼rÃ¼ davranÄ±ÅŸÄ±) kontrolÃ¼ iÃ§erir.
- `start_video_logger1.py`, `start_video_logger2.py`: Hareket algÄ±lanÄ±nca GPS bindirmeli video kaydÄ± yapan yardÄ±mcÄ± scriptler.
- `startall.sh`: QGroundControl, PX4 SITL (iki drone simÃ¼lasyonu) ve drone scriptlerini baÅŸlatmaya yÃ¶nelik yardÄ±mcÄ± script.
- `stop_all.sh`: Sistem sÃ¼reÃ§lerini gÃ¼venli ÅŸekilde kapatÄ±r (PX4, mavsdk_server, loggerler vb.).
- Configuration: `drone1_config.ini`, `drone2_config.ini` (Ã¶rnek iÃ§erik: `[swarm]\nID = 1\nConnection = udp://:14541\nPort = 50051`).

---

### Gereksinimler & HazÄ±rlÄ±k
- PX4 Autopilot (SITL) kurulumu ve build edilmiÅŸ `px4` ikili dosyalarÄ±.
- QGroundControl (isteÄŸe baÄŸlÄ±, uÃ§uÅŸu gÃ¶rselleÅŸtirmek iÃ§in).
- `mavsdk` Python paketi ve `mavsdk_server` Ã§alÄ±ÅŸÄ±r durumda.
- Gerekli Python paketleri (repo kÃ¶kÃ¼nde belirtilenler).

### KonfigÃ¼rasyon
- `drone1_config.ini` ve `drone2_config.ini` iÃ§inde:
  - `ID`: Benzersiz drone kimliÄŸi (Ã¶rn. 1, 2)
  - `Connection`: MAVLink baÄŸlantÄ± stringi (Ã¶rn. `udp://:14541`)
  - `Port`: Scriptte kullanÄ±lan mavsdk portu (Ã¶rn. 50051 / 50052)
- Scriptler config dosyasÄ±nÄ± varsayÄ±lan `~/MasaÃ¼stÃ¼/SP-494/*_config.ini` yolundan okur. KonfigÃ¼rasyon konumunu deÄŸiÅŸtirecekseniz kodu gÃ¼ncelleyin veya sembolik link koyun.

### Telemetry ve PaylaÅŸÄ±lan Bellek
- SHM adÄ±: `telemetry_shared`, boyut: `4096` byte.
- Telemetry kolonlarÄ±: latitude, longitude, absolute_altitude, speed, yaw, battery_percent, satellites_visible vb.
- Her drone telemetry verisini SHM'e yazar; flocking controller diÄŸer dronlarÄ±n konumlarÄ±nÄ± okuyarak koordine hareket saÄŸlar.

---

### AdÄ±m AdÄ±m KullanÄ±m (SimÃ¼lasyon iÃ§in)
1. `startall.sh` ile QGroundControl ve iki PX4 SITL Ã¶rneÄŸini baÅŸlatÄ±n (script terminal baÅŸlÄ±klarÄ± ve beklemeler iÃ§erir).
2. `startall.sh` ayrÄ±ca `drone1.py` / `drone2.py` (veya `ucak1.py`/`ucak2.py`) scriptlerini baÅŸlatÄ±r. Alternatif olarak manuel:
   - `python3 drone1.py` (veya `ucak1.py`)
   - `python3 drone2.py`
3. Hareket baÅŸladÄ±ÄŸÄ±nda video kaydÄ± iÃ§in:
   - `python3 start_video_logger1.py`
   - `python3 start_video_logger2.py`
   Bu scriptler giriÅŸ olarak tanÄ±mlÄ± bir video dosyasÄ±ndan oynatma yapÄ±p GPS bindirmeli bir Ã§Ä±ktÄ± oluÅŸturur (Ã¶rnek yollar script iÃ§inde sabitlenmiÅŸtir, ihtiyaca gÃ¶re gÃ¼ncelleyin).
4. SÃ¼reÃ§leri durdurmak iÃ§in: `./stop_all.sh` (tmux, px4, mavsdk_server ve logger sÃ¼reÃ§lerini sonlandÄ±rÄ±r).

---

### GÃ¼venlik & Operasyonel Notlar
- Scriptler otomatik arming ve takeoff komutlarÄ± gÃ¶nderir; simÃ¼lasyonda test edin, gerÃ§ek uÃ§uÅŸta manuel onay/safeguard ekleyin.
- Kodda arming iÃ§in kÄ±sa beklemeler (4s) ve takeoff sonrasÄ± beklemeler (22â€“25s) bulunur; uÃ§aklarÄ±n stabilize olmasÄ± iÃ§in Ã¶nemlidir.
- SHM oluÅŸturulurken Ã§akÄ±ÅŸma durumlarÄ± ele alÄ±nÄ±r (mevcut alan varsa baÄŸlanÄ±lÄ±r). Script sonlanÄ±nca SHM temizleme (unlink) yapÄ±lÄ±rsa sadece oluÅŸturan kapatÄ±r.
- `stop_all.sh` acil durum kapanÄ±ÅŸÄ± saÄŸlar; gerÃ§ek saha uÃ§uÅŸlarÄ±nda ek gÃ¼venlik katmanlarÄ± (kill switch, fail-safe) ekleyin.

---

### Veri Toplama & Model Entegrasyonu
- Video Ã§Ä±ktÄ±larÄ± GPS metadata ile kaydedilir (scriptler Ã¶rnek sabit yollar kullanÄ±r). GerÃ§ek gÃ¶rÃ¼ntÃ¼ kaydÄ± iÃ§in kamera stream'lerini kaydeden ufak bir logger ile entegre edin.
- Veri pipeline Ã¶nerisi:
  1. VideolarÄ± frame'lere ayÄ±rÄ±n.
  2. Her frame iÃ§in JSON metadata (drone_id, timestamp, lat, lon, alt) oluÅŸturun.
  3. Annotasyon/maske oluÅŸturma: El ile veya semi-otomatik araÃ§larla maskeleri hazÄ±rlayÄ±n ve LoveDA formatÄ±na uygun isimlendirme uygulayÄ±n.
- Online inference: modeli uÃ§akta Ã§alÄ±ÅŸtÄ±rmak yerine yer istasyonunda Ã§alÄ±ÅŸtÄ±rmak daha pratiktir. EÄŸer uÃ§akta Ã§alÄ±ÅŸtÄ±rÄ±lacaksa modeli TorchScript/ONNX'e Ã§evirip quantize ederek dÃ¼ÅŸÃ¼k-latency uygulama hazÄ±rlayÄ±n.

---

### Hata AyÄ±klama & Log'lar
- Terminallerdeki renkli Ã§Ä±ktÄ± (GREEN, YELLOW, RED vb.) ve `[SHM]` mesajlarÄ± hÄ±zlÄ± durum tespiti saÄŸlar.
- MAVSDK baÄŸlantÄ± hatalarÄ±, JSON parse hatalarÄ± veya SHM hatalarÄ± genellikle loglarda gÃ¶rÃ¼nÃ¼r; Ã¶nce bu loglara bakÄ±n.

---

### Ã–rnek Komutlar
- SimÃ¼lasyonu baÅŸlat: `./startall.sh`
- Sadece drone scriptlerini Ã§alÄ±ÅŸtÄ±rmak: `python3 drone1.py & python3 drone2.py &`
- Video kaydÄ± baÅŸlat: `python3 start_video_logger1.py & python3 start_video_logger2.py &`
- Sistemi durdur: `./stop_all.sh`

---

Bu kÄ±lavuz README iÃ§ine eklendi ve sonuna soru eklenmedi.

---

## Model aÄŸÄ±rlÄ±ÄŸÄ± paylaÅŸÄ±mÄ±
Depoda `best_segformer_b3_ema_.pth` dosyasÄ± yer almÄ±yorsa model aÄŸÄ±rlÄ±klarÄ± paylaÅŸÄ±lmamÄ±ÅŸ demektir. Bu yÃ¼zden **eÄŸitimi tekrar etmeniz** gerekli olacaktÄ±r. AÅŸaÄŸÄ±da reproducible eÄŸitim adÄ±mlarÄ± bulunmaktadÄ±r.

### Tekrar EÄŸitim (reproducible) - Ã¶rnek adÄ±mlar:
1. Veri dizinini hazÄ±rla (`/path/to/LoveDa-Dataset`)
2. OrtamÄ± kur: gerekli paketleri yÃ¼kle
3. Kodun `train_segformer` fonksiyonunu iÃ§eren bir script (`train.py`) oluÅŸtur veya mevcut script'i kullan
4. Ã–rnek komut:
```
python train.py --data /path/to/LoveDa-Dataset --epochs 30 --batch-size 8 --lr 1e-4 --device cuda --amp --save-dir ./checkpoints
```
5. En iyi EMA checkpoint: `./checkpoints/best_segformer_b3_ema_.pth`
6. DeÄŸerlendirme / mIoU hesaplama iÃ§in `val` setini kullanÄ±n ve sonuÃ§larÄ± loglayÄ±n

---

## Ä°puÃ§larÄ± & Ä°leri Ã‡alÄ±ÅŸmalar
- Model kÃ¼Ã§Ã¼ltme iÃ§in: ONNX export â†’ quantize (dynamic/static) â†’ uÃ§akta deploy
- Sliding-window veya tile-based inference ile yÃ¼ksek Ã§Ã¶zÃ¼nÃ¼rlÃ¼ gÃ¶rÃ¼ntÃ¼lerde segmentasyon yapÄ±n
- Daha agresif augmentasyonlarla (mixup, cutmix, gridmask) sÄ±nÄ±f dengesizliÄŸini azaltabilirsiniz
- Cross-validation ile daha gÃ¼venilir mIoU elde edebilirsiniz

---

## Dosya YapÄ±sÄ± (Ã–ne Ã‡Ä±kan Dosyalar)
- `segment_and_detect_agriculture.py` â€” segmentasyon ve tarla dÃ¼zeltme mantÄ±ÄŸÄ±
- `ucak1.py`, `ucak2.py` â€” drone entegrasyon scriptleri
- `startall.sh`, `stop_all.sh` â€” Ã§alÄ±ÅŸma scriptleri
- `model_and_test_data/` â€” yardÄ±mcÄ± veriler ve test scriptleri

---